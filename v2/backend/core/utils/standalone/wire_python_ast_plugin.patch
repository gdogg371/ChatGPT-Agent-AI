--- code_bundles/code_bundles/run_pack.py
+++ code_bundles/code_bundles/run_pack.py
@@ -999999,0 +999999,120 @@
+# --- injected: build_cfg wrapper to read packager.yml -------------------------
+# Appends minimal configuration fields to cfg returned by build_cfg(), without
+# touching existing code paths. Safe if packager.yml is absent.
+try:
+    from pathlib import Path as _P
+    try:
+        import yaml as _pm_yaml  # optional
+    except Exception:  # pragma: no cover
+        _pm_yaml = None  # type: ignore
+
+    # Resolve repo root in a way consistent with this module, if available.
+    def _pm__detect_repo_root(cfg=None):
+        try:
+            # If run_pack defines ConfigPaths, use it
+            CP = globals().get("ConfigPaths")
+            if CP is not None:
+                return CP.detect().repo_root
+        except Exception:
+            pass
+        try:
+            if cfg is not None and hasattr(cfg, "repo_root"):
+                return _P(str(cfg.repo_root))
+        except Exception:
+            pass
+        # Fallback to module dirâ€™s parent (project root expectation)
+        return _P(__file__).resolve().parents[4]
+
+    def _pm__read_packager_dict(repo_root: _P) -> dict:
+        if _pm_yaml is None:
+            return {}
+        p = (repo_root / "config" / "packager.yml")
+        if not p.exists():
+            return {}
+        try:
+            return _pm_yaml.safe_load(p.read_text(encoding="utf-8")) or {}
+        except Exception:
+            return {}
+
+    _PM_ORIG_BUILD_CFG = globals().get("build_cfg")
+
+    def _pm__wrapped_build_cfg(*a, **kw):
+        # Call original builder first
+        cfg = _PM_ORIG_BUILD_CFG(*a, **kw) if callable(_PM_ORIG_BUILD_CFG) else None
+        if cfg is None:
+            return cfg
+        try:
+            repo_root = _pm__detect_repo_root(cfg)
+            data = _pm__read_packager_dict(repo_root)
+            for _k in ("metadata_emission", "analysis_filenames", "family_aliases", "controls"):
+                _v = data.get(_k)
+                setattr(cfg, _k, _v if isinstance(_v, dict) else {})
+        except Exception:
+            # Keep cfg unchanged on any error
+            pass
+        return cfg
+
+    # Install wrapper once
+    if callable(_PM_ORIG_BUILD_CFG) and not getattr(_PM_ORIG_BUILD_CFG, "_pm_wrapped", False):
+        globals()["build_cfg"] = _pm__wrapped_build_cfg
+        try:
+            setattr(globals()["build_cfg"], "_pm_wrapped", True)
+        except Exception:
+            pass
+except Exception:
+    # Non-fatal: leave original behavior
+    pass
+# --- end injected -------------------------------------------------------------
--- code_bundles/code_bundles/orchestrate.py
+++ code_bundles/code_bundles/orchestrate.py
@@ -999999,0 +999999,200 @@
+# --- injected: analysis sidecar synthesis from packager.yml -------------------
+# After the normal run completes, append empty-but-valid analysis summaries for
+# families whose emission mode is "both". We write them as 'file' records into
+# the JSONL manifest so downstream checksum/publisher behavior is unchanged.
+try:
+    import json as _json, base64 as _b64, hashlib as _hashlib
+    from pathlib import Path as _P
+    try:
+        import yaml as _yaml  # optional
+    except Exception:  # pragma: no cover
+        _yaml = None  # type: ignore
+
+    def _pm__resolve_class():
+        for _name in ("Packager", "Orchestrator"):
+            _cls = globals().get(_name)
+            if _cls is not None and hasattr(_cls, "run"):
+                return _cls
+        return None
+
+    def _pm__read_packager_dict(repo_root: _P) -> dict:
+        if _yaml is None:
+            return {}
+        p = (repo_root / "config" / "packager.yml")
+        if not p.exists():
+            return {}
+        try:
+            return _yaml.safe_load(p.read_text(encoding="utf-8")) or {}
+        except Exception:
+            return {}
+
+    def _pm__plan_from_cfg(cfg) -> tuple[list[str], dict[str, str], bool]:
+        # Returns (families_to_emit, filename_map, synthesize_flag)
+        try:
+            repo_root = _P(str(getattr(cfg, "repo_root", ".")))
+        except Exception:
+            repo_root = _P(".").resolve()
+        data = _pm__read_packager_dict(repo_root)
+        emission = dict((data.get("metadata_emission") or {}))
+        filenames = dict((data.get("analysis_filenames") or {}))
+        controls = dict((data.get("controls") or {}))
+        synth = bool(controls.get("synthesize_empty_summaries", True))
+
+        defaults = {
+            "asset": "asset.summary.json",
+            "deps": "deps.index.summary.json",
+            "sbom": "sbom.cyclonedx.json",
+            "entrypoints": "entrypoints.summary.json",
+            "env": "env.summary.json",
+            "git": "git.info.summary.json",
+            "io_core": "manifest.summary.json",
+            "license": "license.summary.json",
+            "secrets": "secrets.summary.json",
+            "sql": "sql.index.summary.json",
+            "ast_symbols": "ast.symbols.summary.json",
+            "ast_imports": "ast.imports.summary.json",
+            "ast_calls": "ast.calls.summary.json",
+            "docs": "docs.coverage.summary.json",
+            "quality": "quality.complexity.summary.json",
+            "html": "html.summary.json",
+            "js": "js.index.summary.json",
+            "cs": "cs.summary.json",
+            "codeowners": "codeowners.summary.json",
+        }
+        for k, v in defaults.items():
+            filenames.setdefault(k, v)
+
+        fams = [k for k, v in emission.items() if str(v).lower() == "both"]
+        return fams, filenames, synth
+
+    def _pm__derive_files_scanned(manifest_path: _P) -> int:
+        try:
+            for ln in manifest_path.read_text(encoding="utf-8", errors="replace").splitlines():
+                if '"path": "analysis/contents_index.json"' in ln:
+                    rec = _json.loads(ln)
+                    raw = _b64.b64decode(rec.get("content_b64") or "")
+                    arr = _json.loads(raw.decode("utf-8"))
+                    return int(len(arr))
+        except Exception:
+            pass
+        return 0
+
+    def _pm__append_sidecars(manifest_path: _P, sidecars: dict[str, dict]) -> int:
+        # Append JSONL lines to manifest_path (each 'file' record)
+        if not manifest_path.exists():
+            return 0
+        # Avoid duplicating sidecars if re-run
+        existing = set()
+        try:
+            for ln in manifest_path.read_text(encoding="utf-8", errors="replace").splitlines():
+                if '"type": "file"' in ln and '"path": "analysis/' in ln:
+                    try:
+                        rec = _json.loads(ln)
+                        p = rec.get("path")
+                        if isinstance(p, str):
+                            existing.add(p)
+                    except Exception:
+                        pass
+        except Exception:
+            pass
+
+        added = 0
+        with manifest_path.open("a", encoding="utf-8") as f:
+            for rel_path, obj in sidecars.items():
+                if rel_path in existing:
+                    continue
+                payload = _json.dumps(obj, ensure_ascii=False, sort_keys=True, indent=2).encode("utf-8")
+                rec = {
+                    "type": "file",
+                    "path": rel_path,
+                    "content_b64": _b64.b64encode(payload).decode("ascii"),
+                    "sha256": _hashlib.sha256(payload).hexdigest(),
+                }
+                f.write(_json.dumps(rec, ensure_ascii=False) + "\n")
+                added += 1
+        return added
+
+    _PM_TARGET_CLS = _pm__resolve_class()
+    if _PM_TARGET_CLS is not None:
+        _PM_ORIG_RUN = getattr(_PM_TARGET_CLS, "run", None)
+
+        def _pm__patched_run(self, external_source=None):
+            # Execute original behavior
+            result = _PM_ORIG_RUN(self, external_source)
+            try:
+                fams, filenames, synth = _pm__plan_from_cfg(self.cfg)
+                if not synth or not fams:
+                    return result
+                files_scanned = _pm__derive_files_scanned(self.cfg.out_bundle)
+                sidecars: dict[str, dict] = {}
+                for fam in fams:
+                    name = filenames.get(fam) or f"{fam}.summary.json"
+                    rel = f"analysis/{name}"
+                    sidecars[rel] = {
+                        "kind": str(fam),
+                        "files_scanned": int(files_scanned),
+                        "generated_by": "packager:pm_synth",
+                        "timestamp": None,
+                        "records": [],
+                    }
+                added = _pm__append_sidecars(self.cfg.out_bundle, sidecars)
+                if added:
+                    try:
+                        _log(f"Analysis: synthesized {added} empty summary file(s) per packager.yml")
+                    except Exception:
+                        pass
+            except Exception as e:
+                try:
+                    _log(f"Analysis: synthesize skipped: {type(e).__name__}: {e}")
+                except Exception:
+                    pass
+            return result
+
+        # Install wrapper once
+        if callable(_PM_ORIG_RUN) and not getattr(_PM_ORIG_RUN, "_pm_wrapped", False):
+            setattr(_PM_TARGET_CLS, "run", _pm__patched_run)
+            try:
+                setattr(getattr(_PM_TARGET_CLS, "run"), "_pm_wrapped", True)
+            except Exception:
+                pass
+        else:
+            try:
+                _log("Init: analysis sidecar synthesis already installed or run() not callable")
+            except Exception:
+                pass
+    else:
+        try:
+            _log("Init: Packager/Orchestrator class not found; sidecar synthesis not installed")
+        except Exception:
+            pass
+except Exception as _pm_ex:
+    try:
+        _log(f"Init: analysis sidecar synthesis failed: {type(_pm_ex).__name__}: {_pm_ex}")
+    except Exception:
+        pass
+# --- end injected -------------------------------------------------------------
